#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""aws-deepgram-2026-03 - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Deepgram (Speech-to-Text)
- Aws_Bedrock (LLM)
- Deepgram (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""


from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair, LLMUserAggregatorParams
from loguru import logger
from pipecat.audio.vad.silero import SileroVADAnalyzer
from dotenv import load_dotenv
from pipecat.pipeline.runner import PipelineRunner
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.runner.types import RunnerArguments
import os
from pipecat.transports.base_transport import BaseTransport
from pipecat.runner.types import DailyRunnerArguments
from pipecat.services.deepgram.stt import DeepgramSTTService
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.services.deepgram.tts import DeepgramTTSService
from pipecat.pipeline.pipeline import Pipeline
from pipecat.transports.daily.transport import DailyTransport, DailyParams
from pipecat.services.aws.llm import AWSBedrockLLMService
from pipecat.frames.frames import LLMRunFrame

load_dotenv(override=True)




async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    logger.info("Starting bot")

    # Speech-to-Text service
    stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))

    # Text-to-Speech service
    tts = DeepgramTTSService(
            api_key=os.getenv("DEEPGRAM_API_KEY"),
            voice=os.getenv("DEEPGRAM_VOICE_ID")
        )


    # LLM service
    llm = AWSBedrockLLMService(
        aws_region=os.getenv("AWS_REGION"),
        model=os.getenv("AWS_BEDROCK_MODEL"),
        params=AWSBedrockLLMService.InputParams(temperature=0.8)
    )



    messages = [
        {
            "role": "system",
            "content": "You are a friendly AI assistant. Respond naturally and keep your answers conversational.",
        },
    ]

    context = LLMContext(messages)
    user_aggregator, assistant_aggregator = LLMContextAggregatorPair(
        context,
        user_params=LLMUserAggregatorParams(
            vad_analyzer=SileroVADAnalyzer(),
        ),
    )


    


    # Pipeline - assembled from reusable components
    pipeline = Pipeline([
        transport.input(),

        stt,

        user_aggregator,

        llm,

        tts,

        
        transport.output(),

        
        assistant_aggregator,

    ])


    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        observers=[
        ],
    )

    @task.rtvi.event_handler("on_client_ready")
    async def on_client_ready(rtvi):
        # Kick off the conversation
        await task.queue_frames([LLMRunFrame()])

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info("Client connected")

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info("Client disconnected")
        await task.cancel()




    runner = PipelineRunner(handle_sigint=False)

    await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""
    # Krisp is available when deployed to Pipecat Cloud
    if os.environ.get("ENV") != "local":
        from pipecat.audio.filters.krisp_viva_filter import KrispVivaFilter

        krisp_filter = KrispVivaFilter()
    else:
        krisp_filter = None

    transport = None

    match runner_args:
        case DailyRunnerArguments():
            transport = DailyTransport(
                runner_args.room_url,
                runner_args.token,
                "Pipecat Bot",
                params=DailyParams(
                    audio_in_enabled=True,
                    audio_in_filter=krisp_filter,
                    audio_out_enabled=True,
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    await run_bot(transport)


if __name__ == "__main__":
    from pipecat.runner.run import main

    main()